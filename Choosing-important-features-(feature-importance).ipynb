{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "Choosing important features (feature importance)\n",
    "--------------------------------------------------\n",
    "\n",
    "Feature importance is the technique used to select features using a trained supervised classifier. When we train a classifier such as a decision tree, we evaluate each attribute to create splits; we can use this measure as a feature selector. Let’s understand it in detail.\n",
    "\n",
    "Random forests are among the most popular machine learning methods thanks to their relatively good accuracy, robustness, and ease of use. They also provide two straightforward methods for feature selection—mean decrease impurity and mean decrease accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otto Train data\n",
    "\n",
    "You can download training dataset, train.csv.zip, from the https://www.kaggle.com/c/otto-group-product-classification-challenge/data and place the unzipped train.csv file in your working directory.\n",
    "\n",
    "This dataset describes 93 obfuscated details of more than 61,000 products grouped into 10 product categories (for example, fashion, electronics, and so on). Input attributes are the counts of different events of some kind.\n",
    "\n",
    "The goal is to make predictions for new products as an array of probabilities for each of the 10 categories, and models are evaluated using multiclass logarithmic loss (also called cross entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create Train and Test set from the original dataset \n",
    "def getTrainTestData(dataset,split):\n",
    "    np.random.seed(0) \n",
    "    training = [] \n",
    "    testing = []\n",
    "    np.random.shuffle(dataset) \n",
    "    shape = np.shape(dataset)\n",
    "    trainlength = np.uint16(np.floor(split*shape[0]))\n",
    "    for i in range(trainlength): \n",
    "        training.append(dataset[i])\n",
    "    for i in range(trainlength,shape[0]): \n",
    "        testing.append(dataset[i])\n",
    "    training = np.array(training) \n",
    "    testing = np.array(testing)\n",
    "    return training,testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to evaluate model performance\n",
    "def getAccuracy(pre,ytest): \n",
    "    count = 0\n",
    "    for i in range(len(ytest)):\n",
    "        if ytest[i]==pre[i]: \n",
    "            count+=1\n",
    "    acc = float(count)/len(ytest)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
